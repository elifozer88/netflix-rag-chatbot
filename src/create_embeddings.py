import pandas as pd
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
from pathlib import Path

# Windows ve Linux'te Ã§alÄ±ÅŸan path
data_dir = Path('data')
faiss_dir = Path('faiss_index')
input_file = data_dir / 'cleaned_netflix.csv'
index_file = faiss_dir / 'netflix_faiss.index'
metadata_file = faiss_dir / 'netflix_metadata.csv'

# KlasÃ¶rleri oluÅŸtur
faiss_dir.mkdir(exist_ok=True)

# Dosya var mÄ± kontrol et
if not input_file.exists():
    print(f"âŒ Dosya bulunamadÄ±: {input_file}")
    print(f"ğŸ’¡ Ã–nce preprocess_data.py'Ä± Ã§alÄ±ÅŸtÄ±r")
    exit(1)

# TemizlenmiÅŸ veriyi yÃ¼kle
print(f"ğŸ“– Veri yÃ¼kleniyor: {input_file}")
df = pd.read_csv(input_file)
print(f"âœ… YÃ¼klendi: {len(df)} satÄ±r")

# Embedding modeli indir (ilk kez uzun sÃ¼rer)
print("ğŸ”¹ Embedding modeli yÃ¼kleniyor...")
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

# Her content iÃ§in embedding oluÅŸtur
print("ğŸ”¹ Embedding'ler oluÅŸturuluyor (bu biraz zaman alabilir)...")
embeddings = model.encode(df['content'].tolist(), show_progress_bar=True)

# NumPy array'e Ã§evir
embeddings = np.array(embeddings).astype("float32")
print(f"âœ… {len(embeddings)} embedding oluÅŸturuldu")

# FAISS index oluÅŸtur
print("ğŸ”¹ FAISS index oluÅŸturuluyor...")
index = faiss.IndexFlatL2(embeddings.shape[1])
index.add(embeddings)

# Kaydet
print(f"ğŸ’¾ Kaydediliyor...")
faiss.write_index(index, str(index_file))
df.to_csv(metadata_file, index=False)

print("âœ… FAISS veritabanÄ± baÅŸarÄ±yla kaydedildi!")
print(f"   ğŸ“ Index: {index_file}")
print(f"   ğŸ“ Metadata: {metadata_file}")
print(f"   ğŸ“Š Toplam embedding: {len(embeddings)}")
print(f"   ğŸ¯ Embedding boyutu: {embeddings.shape[1]}")