import pandas as pd
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
import google.generativeai as genai
import os
from pathlib import Path
from dotenv import load_dotenv

# .env dosyasÄ±ndan ortam deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Gemini'yi yapÄ±landÄ±r
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel('gemini-2.0-flash')
else:
    raise ValueError("GEMINI_API_KEY bulunamadÄ±! .env dosyasÄ±nÄ± kontrol et.")

class RAGPipeline:
    def __init__(self, index_path="faiss_index/netflix_faiss.index", 
                 metadata_path="faiss_index/netflix_metadata.csv",
                 model_name="sentence-transformers/all-MiniLM-L6-v2"):
        """
        RAG pipeline'Ä± baÅŸlat
        - FAISS indexini yÃ¼kle
        - Metadata CSV'sini yÃ¼kle
        - Embedding modelini yÃ¼kle
        """
        # EÄŸer src/ klasÃ¶rÃ¼nden Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yorsa, Ã¼st klasÃ¶re Ã§Ä±k
        if Path("../faiss_index").exists():
            base_dir = Path("..")
        else:
            base_dir = Path(".")
        
        # Path'leri pathlib ile dÃ¼zelt (Windows uyumlu)
        index_path = base_dir / index_path if isinstance(index_path, str) else index_path
        metadata_path = base_dir / metadata_path if isinstance(metadata_path, str) else metadata_path
        
        # Dosya kontrolÃ¼
        if not index_path.exists():
            raise FileNotFoundError(f"FAISS index bulunamadÄ±: {index_path.absolute()}")
        if not metadata_path.exists():
            raise FileNotFoundError(f"Metadata dosyasÄ± bulunamadÄ±: {metadata_path.absolute()}")
        
        # FAISS ve metadata yÃ¼kle
        self.index = faiss.read_index(str(index_path))
        self.df = pd.read_csv(str(metadata_path))
        self.embedding_model = SentenceTransformer(model_name)
        print(f"âœ… RAG Pipeline baÅŸlatÄ±ldÄ± (Gemini ile)")
        print(f"ğŸ“Š Toplam {len(self.df)} iÃ§erik yÃ¼klendi")

    def retrieve(self, query, top_k=5):
        """
        Sorguyu al ve FAISS ile en yakÄ±n top_k iÃ§eriÄŸi getir
        """
        # Sorguyu embedding'e Ã§evir
        query_embedding = self.embedding_model.encode([query])
        query_embedding = np.array(query_embedding).astype("float32")
        
        # FAISS'te arama yap
        distances, indices = self.index.search(query_embedding, top_k)
        
        # SonuÃ§larÄ± dÃ¶ndÃ¼r
        results = self.df.iloc[indices[0]]
        return results

    def generate_answer(self, query, top_k=5):
        """
        1. Retrieval: En yakÄ±n iÃ§erikleri bul
        2. Augmentation: Context olarak dÃ¼zenle
        3. Generation: Gemini ile yanÄ±t oluÅŸtur
        """
        # Retrieval
        docs = self.retrieve(query, top_k)
        
        # Context oluÅŸtur
        context_text = "\n\n".join([
            f"BaÅŸlÄ±k: {row['title']}\nTÃ¼r: {row['listed_in']}\nAÃ§Ä±klama: {row['description']}" 
            for _, row in docs.iterrows()
        ])

        # Prompt hazÄ±rla
        prompt = f"""Soru: {query}

AÅŸaÄŸÄ±daki Netflix iÃ§erikleri veriliyor:
{context_text}

YukarÄ±daki bilgileri kullanarak soruyu TÃ¼rkÃ§e olarak cevapla. YanÄ±tÄ±nda hangi film/dizileri referans aldÄ±ÄŸÄ±nÄ± belirt. KÄ±sa ve Ã¶z cevap ver."""

        # Gemini'den yanÄ±t al
        try:
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            return f"âŒ Gemini API HatasÄ±: {str(e)}\n\nğŸ’¡ GEMINI_API_KEY kontrolÃ¼nÃ¼ yap."